{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30410305, 0.04744781, 0.70768859])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "# dot product란 X와 theta를 곱하는 방식으로 생각해주면 된다. Logistic function에 사용하기 위함. \n",
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \\frac{1}{1 + e^{-(X_i\\theta)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1  / (1 + np.exp(-z) )  # exp 함수는 지수함수라고 생각하면 된다. \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.596637784833088"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p) = - \\Sigma(y_{i}\\log p(X_{i}) + (1 - y_{i}) \\log(1 - p(X_{i}))) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters) # p는 위의 logistic 공식 그대로 사용\n",
    "    loss = (y * np.log(p) + (1-y) * np.log(1-p)) #위의 목적함수 그대로 numpy로구현\n",
    "    return loss # loss 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = np.dot(X, parameters.T)\n",
    "    loss = ((y - y_hat) ** 2) /2 # 지수함수를 사용하여 loss 함수를 구하는 것을 의미한다, L2 norm 이라고도 불린다. \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X,y, parameters)\n",
    "    loss = loss/n  #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0048785132702027"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)=$ $ -\\Sigma(y_{i} - \\theta^{T}X_{i})X_{ij} $\n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)=$ $ -\\Sigma(y_{i} - p_{i})X_{ij} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "# j 를 이용하여 손실함수를 업데이트 한다. \n",
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = np.dot(X, parameters.T)\n",
    "        gradient = (y - y_hat) * X[j] #파라미터 업데이트하기 \n",
    "    else:\n",
    "        p = logistic(X, parameters)\n",
    "        gradient = (y - p) * X[j]\n",
    "    return - gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11678379458093194"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "#Image(\"C:/Users/rhskr/Desktop/배치알고리즘_구현.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model) # 손실함수 그대로 사용하기 \n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42.83422139265658, 0.8000414850749183, 38.371249317363464]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명:  batch size 는 parameter 를 업데이트할때 데이터를 분할 하는 것을 의미한다. 특히 train에서 아주 중요한 역할을 하게 된다. 위의 batch_idx함수 역시 batch size를 나눠주는 역할을 하여 리소스를 잘 활용하여 학습시간을 효율적으로 사용할 수 있도록 하게 해준다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n # 평균으로 한다.\n",
    "    \n",
    "    parameters -= gradients # gradients 로 업데이트한 값\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30124743, 0.04739448, 0.70513051])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch:  현재 진행되고 있는 데이터셋을 반복하는 횟수 \n",
    "- num_epoch: 전체 데이터셋을 학습 한 횟수\n",
    "<br>\n",
    "\n",
    "BGD: 모든 데이터를 다 고려하여 최적의 optimum으로 도달하는 방식 \n",
    "SGD: batch 단위로 loss function을 계산한다. \n",
    "MGD: 학습 한번에 데이터셋 일부에 대해서만 기울기를 구하는 것을 말한다.  \n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> SGD \n",
    "batch_size=k -> MGD  \n",
    "batch_size=whole -> BGD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i # logictic 함수라면 cross entropy 함수를 사용, 아니면 mse\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(X_batch))\n",
    "            new_loss = batch_loss(X_batch,y_batch, parameters, loss_function, len(X_batch))\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: -0.6894048325140325  params: [0.07901047 0.71946904 0.01247721]  gradients: [0.024159336082723307, 0.005162223501721843, 0.022475795682021252]\n",
      "epoch: 100  loss: -0.42792138824310266  params: [-0.87851018  1.07494434 -0.98636713]  gradients: [0.0032107364116564785, -0.005334672181465607, 0.00567869021755905]\n",
      "epoch: 200  loss: -0.3800140296093285  params: [-1.06826332  1.54184915 -1.45448846]  gradients: [0.0012185631505153207, -0.0040312654311804195, 0.0039411320410405095]\n",
      "epoch: 300  loss: -0.3547418657740303  params: [-1.16720548  1.89430747 -1.79724445]  gradients: [0.0008388667252483965, -0.0030948831140194537, 0.0029970067449781343]\n",
      "epoch: 400  loss: -0.3393869908553128  params: [-1.24241995  2.17053204 -2.06392119]  gradients: [0.0006813547412486321, -0.002475395486321502, 0.0023826720455954347]\n",
      "epoch: 500  loss: -0.3292911803500494  params: [-1.30501555  2.39498845 -2.27942455]  gradients: [0.0005768548883039943, -0.002041754048940035, 0.001955429174917265]\n",
      "epoch: 600  loss: -0.3222823245921825  params: [-1.35849086  2.58228372 -2.45841796]  gradients: [0.0004965865929031806, -0.0017224303360606921, 0.001642629426771057]\n",
      "epoch: 700  loss: -0.3172196764960531  params: [-1.40478741  2.74166616 -2.61013894]  gradients: [0.0004322298033109475, -0.0014778243239901227, 0.0014042696584626092]\n",
      "epoch: 800  loss: -0.313451083047523  params: [-1.44526767  2.87933415 -2.74074904]  gradients: [0.0003795954220678487, -0.0012846286622671939, 0.001216890307316023]\n",
      "epoch: 900  loss: -0.3105789319966027  params: [-1.48095615  2.99964111 -2.85455612]  gradients: [0.0003359200695364879, -0.0011283113753836301, 0.0010659200642985278]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.51234432,  3.10476335, -2.95374725])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train, batch_size = X_train.shape[0])\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "x0H5tnauLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: -0.4409334250788394  params: [-0.54070869  0.62298446 -0.56496917]  gradients: [0.037728684359454666, 0.029896827770675587, 0.0356950754835798]\n",
      "epoch: 100  loss: -0.14035638983069657  params: [-1.86536715  4.16400372 -3.97536437]  gradients: [0.012719044107349899, 0.011357783074298335, 0.010585310011911856]\n",
      "epoch: 200  loss: -0.13877645351411846  params: [-1.88693906  4.23166779 -4.03755892]  gradients: [0.01257453839871625, 0.011253432704718656, 0.010457393602597459]\n",
      "epoch: 300  loss: -0.1387089204697887  params: [-1.88787529  4.23460359 -4.04025563]  gradients: [0.012568361846591635, 0.011248970972255905, 0.010451936007687646]\n",
      "epoch: 400  loss: -0.13870594042675463  params: [-1.88791663  4.23473322 -4.0403747 ]  gradients: [0.012568089293208986, 0.011248774085934977, 0.010451695198518613]\n",
      "epoch: 500  loss: -0.1387058087442631  params: [-1.88791845  4.23473895 -4.04037996]  gradients: [0.01256807724958902, 0.01124876538589397, 0.010451684557652071]\n",
      "epoch: 600  loss: -0.13870580292510737  params: [-1.88791854  4.2347392  -4.04038019]  gradients: [0.012568076717371713, 0.011248765001432109, 0.010451684087423646]\n",
      "epoch: 700  loss: -0.13870580266795382  params: [-1.88791854  4.23473922 -4.0403802 ]  gradients: [0.012568076693852554, 0.011248764984442404, 0.010451684066643827]\n",
      "epoch: 800  loss: -0.1387058026565899  params: [-1.88791854  4.23473922 -4.0403802 ]  gradients: [0.012568076692813231, 0.011248764983691619, 0.010451684065725556]\n",
      "epoch: 900  loss: -0.13870580265608787  params: [-1.88791854  4.23473922 -4.0403802 ]  gradients: [0.012568076692767308, 0.011248764983658444, 0.010451684065684983]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.88791854,  4.23473922, -4.0403802 ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train, batch_size = 3)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "iGfXGoJaLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: -0.84580323835564  params: [ 0.29628004  0.82552903 -0.06110323]  gradients: [0.030770952961280722, 0.020367919840946512, 0.041029543018431994]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.9796991 ,  1.33343165, -1.27955212])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_mgd = gradient_descent(X_train, y_train, batch_size = 32)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 4,  6]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47748446, 2.85342265])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "M74iqj4WLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.44156789739589725  params: [1.23136553 1.16964249]  gradients: [-0.04551779373500924, -0.024301362247471037]\n",
      "epoch: 100  loss: 0.3844480526529701  params: [0.55946843 2.85924292]  gradients: [-0.040084406373925796, -0.016903902149980762]\n",
      "epoch: 200  loss: 0.3845837152316007  params: [0.55737039 2.86332813]  gradients: [-0.040124958150875634, -0.01690888903657526]\n",
      "epoch: 300  loss: 0.3845840603782751  params: [0.55736507 2.8633385 ]  gradients: [-0.04012506108045821, -0.01690890169442146]\n",
      "epoch: 400  loss: 0.3845840612543407  params: [0.55736505 2.86333853]  gradients: [-0.04012506134171677, -0.016908901726549935]\n",
      "epoch: 500  loss: 0.38458406125656436  params: [0.55736505 2.86333853]  gradients: [-0.040125061342379906, -0.016908901726631488]\n",
      "epoch: 600  loss: 0.38458406125657  params: [0.55736505 2.86333853]  gradients: [-0.040125061342381585, -0.01690890172663169]\n",
      "epoch: 700  loss: 0.38458406125657  params: [0.55736505 2.86333853]  gradients: [-0.040125061342381585, -0.01690890172663169]\n",
      "epoch: 800  loss: 0.38458406125657  params: [0.55736505 2.86333853]  gradients: [-0.040125061342381585, -0.01690890172663169]\n",
      "epoch: 900  loss: 0.38458406125657  params: [0.55736505 2.86333853]  gradients: [-0.040125061342381585, -0.01690890172663169]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55736505, 2.86333853])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, model = 'linear')\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijgIcAdGLMbA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
